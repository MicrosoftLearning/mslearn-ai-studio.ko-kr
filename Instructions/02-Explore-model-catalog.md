---
lab:
  title: 'Azure AI Foundry에서 언어 모델 탐색, 배포, 채팅'
---

# Azure AI Foundry에서 언어 모델 탐색, 배포, 채팅

Azure AI Foundry의 모델 카탈로그는 다양한 모델을 탐색하고 사용할 수 있는 중앙 리포지토리 역할을 하므로 생성형 AI 시나리오를 쉽게 만들 수 있습니다.

이 연습에서는 Azure AI Foundry 포털의 모델 카탈로그를 살펴봅니다.

이 연습은 약 **25**분 정도 소요됩니다.

## Azure AI 허브 및 프로젝트 만들기

Azure AI 허브는 하나 이상의 *프로젝트*를 정의할 수 있는 공동 작업 영역을 제공합니다. 프로젝트와 Azure AI 허브를 만들어 보겠습니다.

1. 홈페이지에서 **+ 프로젝트 만들기**를 선택합니다. **프로젝트 만들기** 마법사에서는 프로젝트를 통해 자동으로 만들어지는 모든 Azure 리소스를 보거나, **만들기**를 선택하기 전에 **사용자 지정**을 선택하여 다음 설정을 사용자 지정할 수 있습니다.

    - **허브 이름**: *고유 이름*
    - **구독**: ‘Azure 구독’
    - **리소스 그룹**: *새 리소스 그룹*
    - **위치**: **선택 도움말**을 선택한 다음 위치 도우미 창에서 **gpt-35-turbo**를 선택하고 추천 지역을 사용합니다.\*
    - **Azure AI 서비스 또는 Azure OpenAI 연결**: (신규) *선택한 허브 이름으로 자동 채우기*
    - **Azure AI 검색 연결**: 연결 건너뛰기

    > \* Azure OpenAI 리소스는 지역 할당량에 따라 테넌트 수준에서 제한됩니다. 위치 도우미에 나열된 지역에는 이 연습에 사용된 모델 유형에 대한 기본 할당량이 포함되어 있습니다. 지역을 무작위로 선택하면 단일 지역이 할당량 한도에 도달할 위험이 줄어듭니다. 연습 후반부에 할당량 한도에 도달하는 경우 다른 지역에서 다른 리소스를 만들어야 할 수도 있습니다. [지역별 모델 가용성](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-35-turbo-model-availability)에 대해 자세히 알아보기

1. **사용자 지정**을 선택한 경우 **다음**을 선택하고 구성을 검토합니다.
1. 1. **만들기**를 선택하고 프로세스가 완료될 때까지 기다립니다.
   
    Azure AI 허브와 프로젝트가 만들어지면 다음 이미지와 유사하게 표시됩니다.

    ![Azure AI Foundry 포털의 Azure AI 허브 세부 정보 스크린샷.](./media/azure-ai-resource.png)

1. 새 브라우저 탭을 열고(Azure AI Foundry 포털 탭은 열어둔 상태) Azure Portal([https://portal.azure.com](https://portal.azure.com?azure-portal=true))로 이동한 뒤 메시지가 표시되면 Azure 자격 증명으로 로그인합니다.
1. Azure AI 허브를 만든 리소스 그룹으로 이동하여 생성된 Azure 리소스를 확인합니다.

    ![Azure Portal의 Azure AI 허브 및 관련 리소스 스크린샷.](./media/azure-portal.png)

1. Azure AI Foundry 포털 브라우저 탭으로 돌아갑니다.
1. 페이지의 왼쪽에 있는 창에서 Azure AI 허브의 각 페이지를 확인하고, 생성 및 관리할 수 있는 아티팩트를 확인합니다. **관리 센터** 페이지의 허브 또는 프로젝트 아래에서 **연결된 리소스**를 선택하여 Azure OpenAI 및 AI 서비스에 대한 연결이 이미 만들어졌는지 확인할 수 있습니다.
1. 지금 관리 센터 페이지에 있다면 **프로젝트로 이동**을 선택합니다.

## 모델 벤치마크를 사용하여 모델 선택

모델을 배포하기 전에 모델 벤치마크를 탐색하여 요구 사항에 가장 적합한 모델을 결정할 수 있습니다.

여행 도우미 역할을 하는 사용자 지정 Copilot 만들기를 원한다고 가정해봅니다. 특히, Copilot이 비자 요구 사항, 일기 예보, 지역 관광 명소, 문화 규범과 같은 여행 관련 문의에 대한 지원을 제공하기를 원합니다.

Copilot은 실제로 정확한 정보를 제공해야 하므로 근거가 중요합니다. 그 다음, Copilot의 대답은 읽고 이해하기 쉬워야 합니다. 따라서 유창성과 일관성도 높은 모델을 선택하는 것이 좋습니다.

1. Azure AI Foundry 프로젝트 포털에서 왼쪽 메뉴를 사용하여 **모델 벤치마크**로 이동합니다.
    **품질 벤치마크** 탭에서 이미 시각화된 일부 차트를 찾아 다른 모델을 비교할 수 있습니다.
1. 표시된 모델을 필터링합니다.
    - **Tasks**: 질문 답변
    - **컬렉션**: Azure OpenAI
    - **메트릭**: 일관성, 유창성, 근거
1. 결과 차트와 비교 테이블을 탐색합니다. 탐색할 때 다음 질문에 대답할 수 있습니다.
    - Do you notice a difference in performance between GPT-3.5 and GPT-4 models?
    - Is there a difference between versions of the same model?
    - How do the 32k variants differ from the base models?

Azure OpenAI 컬렉션에서 GPT-3.5와 GPT-4 모델 중에서 선택할 수 있습니다. 두 모델을 배포하고 사용 사례와 비교하는 방법을 살펴보겠습니다.

## Azure OpenAI 모델 배포

이제 모델 벤치마크를 통해 옵션을 살펴보셨으므로 언어 모델을 배포할 준비가 되었습니다. 모델 카탈로그를 찾아보고 카탈로그에서 배포하거나, **배포** 페이지를 통해 모델을 배포할 수 있습니다. 두 옵션을 모두 살펴보겠습니다.

### 모델 카탈로그에서 모델 배포

먼저 모델 카탈로그에서 모델을 배포해 보겠습니다. 사용 가능한 모든 모델을 필터링하려는 경우 이 옵션을 사용할 수 있습니다.

1. 왼쪽 메뉴를 사용하여 **모델 카탈로그** 페이지로 이동합니다.
1. Azure AI에서 큐레이팅한 `gpt-35-turbo` 모델을 검색하고 배포합니다. 이때 배포 세부 정보에서 **사용자 지정**을 선택하여 다음 설정을 사용합니다.
   
    - **배포 이름**: *모델 배포에 대한 고유한 이름*
    - **배포 유형**: 표준
    - **모델 버전**: *기본 버전 선택*
    - **AI 리소스**: *이전에 만든 리소스 선택*
    - **분당 토큰 속도 제한(천 )**: 5K
    - **콘텐츠 필터**: DefaultV2
    - **동적 할당량 사용**: 사용할 수 없음

### 모델 + 엔드포인트를 통한 모델 배포

배포하려는 모델을 정확히 알고 있는 경우 **모델 + 엔드포인트**를 통해 배포를 수행하는 것이 좋습니다.

1. 왼쪽 메뉴를 사용하여 **자산** 섹션 아래의 **모델 + 엔드포인트** 페이지로 이동합니다.
1. **모델 배포** 탭의 배포 세부 정보에서 **사용자 지정**을 선택하여 다음 설정으로 새 베이스 모델을 배포합니다.
    - **모델**: gpt-4
    - **배포 이름**: *모델 배포에 대한 고유한 이름*
    - **배포 유형**: 표준
    - **모델 버전**: *기본 버전 선택*
    - **AI 리소스**: *이전에 만든 리소스 선택*
    - **분당 토큰 속도 제한(천 )**: 5K
    - **콘텐츠 필터**: DefaultV2
    - **동적 할당량 사용**: 사용할 수 없음

    > **참고**: 배포하려는 모델에 사용할 수 있는 할당량이 현재 AI 리소스 위치에 없는 경우 다른 위치를 선택하여 새 AI 리소스를 만들고 프로젝트에 연결하라는 메시지가 표시됩니다.

## 채팅 플레이그라운드에서 모델 테스트

이제 비교할 두 가지 모델이 있으므로 대화형 상호 작용에서 모델이 어떻게 동작하는지 살펴보겠습니다.

1. 왼쪽 메뉴를 사용하여 **플레이그라운드** 페이지로 이동합니다.
1. **채팅 플레이그라운드**에서 GPT-3.5 배포를 선택합니다.
1. 채팅 창에 `What can you do?`와 같은 쿼리를 입력하고 응답을 확인합니다.
    대답은 매우 일반적입니다. 여행 도우미 역할을 하는 사용자 지정 Copilot 만들기를 원합니다. 질문에서 원하는 도움말 종류를 지정할 수 있습니다.
1. 채팅 창에서 쿼리 `Imagine you're a travel assistant, what can you help me with?`를 입력합니다. 답변은 이미 더 구체적입니다. 최종 사용자가 Copilot과 상호 작용할 때마다 필요한 컨텍스트를 제공하지 않도록 할 수 있습니다. 전역 지침을 추가하기 위해 시스템 메시지를 편집할 수 있습니다.
1. **설정**에서 **모델 지침 및 컨텍스트 제공** 필드를 다음 프롬프트로 업데이트합니다.

   ```
   You are an AI travel assistant that helps people plan their trips. Your objective is to offer support for travel-related inquiries, such as visa requirements, weather forecasts, local attractions, and cultural norms.
   ```

1. **변경 내용 적용**을 선택합니다.
1. 채팅 창에서 쿼리 `What can you do?`를 입력하고 새 응답을 봅니다. 이전에 받은 답변과 어떻게 다른지 관찰합니다. 이제 대답은 여행에 특정합니다.
1. `I'm planning a trip to London, what can I do there?`를 질문하여 대화를 계속합니다. Copilot에게 여행 관련 정보를 많이 제공합니다. 출력을 계속 개선할 수 있습니다. 예를 들어 대답이 더 간결하게 표시되도록 할 수 있습니다.
1. 메시지의 끝에 `Answer with a maximum of two sentences.`를 추가하여 시스템 메시지를 업데이트합니다. 변경 내용을 적용하고, 채팅을 지우고, `I'm planning a trip to London, what can I do there?`를 질문하여 채팅을 다시 테스트합니다. 또한 단순히 질문에 대답하는 대신 Copilot과 대화를 계속할 수도 있습니다.
1. 프롬프트의 끝에 `End your answer with a follow-up question.` 문구를 추가하여 모델의 컨텍스트를 업데이트합니다. 변경 사항을 저장하고 다음 질문을 보내서 다시 채팅을 테스트합니다. `I'm planning a trip to London, what can I do there?` 
1. **배포**를 GPT-4 모델로 변경하고 이 섹션의 모든 단계를 반복합니다. 모델이 출력에서 어떻게 달라질 수 있는지 확인합니다.
1. 마지막으로 쿼리 `Who is the prime minister of the UK?`에서 두 모델을 모두 테스트합니다. 이 질문에 대한 성능은 모델의 근거(응답이 실제로 정확한지 여부)와 관련이 있습니다. 성능은 모델 벤치마크의 결론과 관련이 있나요?

이제 두 모델을 모두 살펴보았으므로 사용 사례에 대해 지금 선택할 모델을 고려합니다. 처음에는 모델의 출력이 다를 수 있으며 다른 모델보다 한 모델을 선호할 수 있습니다. 그러나 시스템 메시지를 업데이트한 후에는 차이가 최소화된 것을 알 수 있습니다. 비용 최적화 관점에서 GPT-4 모델보다 GPT-3.5 모델을 선택할 수 있습니다. 성능은 매우 유사합니다.

## 정리

Azure AI Foundry 포털 탐색을 완료한 경우 불필요한 Azure 비용이 발생하지 않도록 이 연습에서 만든 리소스를 삭제해야 합니다.

1. Azure Portal이 포함된 브라우저 탭으로 돌아가서(또는 새 브라우저 탭에서 [Azure Portal](https://portal.azure.com?azure-portal=true)을 다시 열고) 이 연습에 사용된 리소스를 배포한 리소스 그룹의 콘텐츠를 확인합니다.
1. 도구 모음에서 **리소스 그룹 삭제**를 선택합니다.
1. 리소스 그룹 이름을 입력하고 삭제할 것인지 확인합니다.
